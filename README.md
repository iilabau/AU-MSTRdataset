
## AU-MSTR: A Multi-script Scene Text Reading Dataset

A multi-script indoor-outdoor scene image dataset is developed for text detection, referred to as Aliah University-Multi-script Scene Text Reading (AU-MSTR) dataset.
Digital cameras built in handheld devices such as cellphones, smart phones, portable digital assistants (PDAs), etc. are used for preparation of this dataset due to its fast and easy image acquisition capability under unconstrained environments. In this dataset, word level annotation is prepared for text detection task. Ground Truth (GT) file of each image is prepared separately and included in respective directory.
Images are captured under unconstraint environment using multiple cameras with varying focal length that generates perpective distorted image. Images are also captured in day-light and night, that certainly augment additional challenges for scene text detection.

### Dataset Summary

Images of AU-MSTR dataset are captured in indoor as well as outdoor environments. Indoor images are mainly captured from bottles, pens, packets, other household accessories etc. whereas outdoor scene images are captured from poster, banner, traffic sign-boards, wall paintings, buildings and other real-life sources. This dataset comprises of a total of 569 scene text images acquired with cell-phone cameras of different resolutions, highest being 12 megapixels. Total images are divided into 2:1 ratio for training and testing. This dataset is comprised of four classes of scripts viz. Latin, Devanagari, Bengali, and Mixed. Image of mixed class are embedded with texts of more than one scripts out of three scripts. A brief outline of AU-MSTR dataset with script-wise image distribution is showsn below:

Script:
  1. Latin: Training set-121, Test set-61, Total-182
  2. Bengali: Training set-75, Test set-37, Total-112
  3. Devanagari: Training set-89, Test set-44, Total-133
  4. Mixed: Training set-94, Test set-48, Total-142
  
Total training images -379, Total test images-190, Total images-569


### Relevant Paper
The following paper may be consulted and cited while referring to this dataset.
> **T. Khan and A. F. Mollah, "A novel multi-scale deep neural framework for script invariant text detection" (Communicated)**

### Contributors
- Mr. Tauseef Khan, Senuior Research Fellow, Department of Computer Science and Engineering, Aliah University, IIA/27 NewTown, Kolkata 700160, India
- Dr. Ayatullah Faruk Mollah, 
Department of Computer Science and Engineering, 
Aliah University, India

### Contact
Mr. Tauseef Khan, Email: tauseef.hit2013@gmail.com
